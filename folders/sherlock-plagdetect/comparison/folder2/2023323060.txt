 As the memory chip density increases, errors occur more frequently. Thus, various Error Correction Code (ECC) designs are implemented to mitigate errors. The modern memory vendors have adopted 2-level ECC architectures consisting of ECCs, and Error Detection Codes (EDCs). This is because when the number of errors exceeds the correction capability of ECC, ECC may lead to error miscorrection.  To avoid a system failure caused by miscorrections, EDCs should verify the integrity of the corrected data in accordance with ECCs. However, efficient methods of ECC/EDC co-design in modern 2-level architectures have not yet been studied. By enhancing ECC capability and bounding side effects in the range of EDC capability, the reliability of memory systems can be improved significantly. For example, ECC capability can be enhanced without extra data using the prediction method, which considers errors observed most frequently in modern memory systems. When memory errors occur in such as automotive or medical devices, the effects can be fatal to humans. The proposed research can help enhance reliability, thereby facilitating userâ€™s safety. As the density, capacity, and bandwidth of Dynamic Random Access Memory (DRAM) have increased, faults and errors occurred more frequently, which result in significant reliability issues. For this reason, error correction codes (ECCs) are widely used in DRAMs to mitigate faults and errors. However, ECC requires extra check bits to be stored in DRAM, which is critical overhead. Thus, various techniques have been proposed to enhance the reliability without extra check bits. In [1], possibility of error correction is increased by grouping data that can be affected by faults of the same DRAM component. For not only enhanced reliability but practical correction capability, method of [2] applied strong ECC and normal ECC to weak cells and normal cells, respectively after classifying manufactured memory cells by the physical properties as weak and normal cells.To increase correction rate for all error cases,  the method of [3] based on splitting and interleaving the data established more correction-flexible data structure.      To increase the Mean Time Between Failure (MTBF) of Dynamic Random Access Memory (DRAM), Error Correction Codes (ECCs) and Error Detection Codes (EDCs) are widely used. Moreover, the capabilities to correct/detect errors have increased, which requires more additional check bits. Recently, two-tiered ECC architectures that use two ECCs [1] or both an ECC and EDC [2-4] have been adopted to correct more errors. In [1], each ECC covers part of the data, which enables multiple intermittent errors to be corrected. In [2-4], the EDC checks the data accuracy by detecting the remaining errors after the ECC corrects the errors. Concerning implementations that affect the correction/detection capability of ECC, [2-3] used multiple ECCs to split data, whereas [4] used a single ECC without split. Therefore, this research project considers the reliability of two-tiered ECC architectures, the design methodology of ECCs, and enhanced correction capability by additional modifications of ECC.  RQ 1. To what extent is the co-design of ECC and EDC more effective than using two ECCs in terms of the MTBF of DRAMs.  RQ 2. To what extent is splitting data with multiple ECCs more effective than not splitting data with a single ECC in terms of error correction capability.  RQ 3. To what extent can modifying ECC and EDC in a two-tiered ECC architecture increase error correction capability without a drop of error detection capability.            To address the synergetic design for enhanced DRAM reliability, a two-tiered ECC architecture consisting of two types of codes are proposed [1-4], which measure the reliability for various errors to establish a synergetic design. Specifically, two-tiered ECC architectures build upon previous studies of DRAM error characteristics that identify the most frequent errors in DRAM.  Reliability measurement often involves assessing the mean time to failure by testing operating chips. However, conducting tests on numerous real chips results in excess  costs.Consequently, simulation results based on programming for all error cases are prevalent in the literature [1-2]. Error correction capability and detection capability are quantified by calculating the number of corrected errors and the number of detected errors compared to the number of simulated error cases. To compare the correction/detection capabilities of different designs, the number of corrected/detected errors for the same group of error cases is analyzed. However, considering all errors associated with 128-bit data, simulating the required number of cases, which is 2^128-1, is impractical. Thus, algebraic calculation of the ECC algorithm is also prevalent in the industry [5-6]. Utilizing an established ECC algorithm ensures accurate calculation of the correction/detection capabilities.     To answer the above questions addressing DRAM reliability, simulations for error injection and result observations are required. To compare the reliability, correction/detection results for the same errors are used. For correction capability, whether original data is recovered is used. While correctable errors are limited to accurately and simply, the calculation of detectable errors is very complex. The number of detectable errors overwhelms the correctable errors. Moreover, the interactive effect of the detection of each ECC in the two-tiered ECC architecture is very complex. For an accurate comparison of reliability, all errors should be considered. However, the number of all possible errors is too large to simulate, e.g., 340 undecillion for 128-bit data.   In [1], and [2], to measure practical reliability, a DRAM simulator with benchmark software is used. In [3], [4], [5], reliability for errors indicated by previous studies [5], [6], [7] as the most frequently occurring in DRAM is measured. In terms of RQ3, which emerged as an important issue,  simulations with adjacent error injection can be used.      For an exact measurement of the error correction capability of an Error Correction Code (ECC) in Dynamic Random Access Memory (DRAM), all possible errors for data should be considered, which is very time-consuming. When the size of the data increases linearly, the number of all possible errors increases exponentially, which makes the accurate simulation impractical. For example, in the case of 128-bit data, the number of all possible errors exceeds 340 undecillion. In [1], and [2], software-based DRAM simulators with benchmark sub-software are used for approximate measurement of the correction capability. For more accurate measurements, [3],and [4] leveraged the previous works that have studied the frequency of DRAM errors in the field. They simulated all possible cases of the representative errors indicated by the previous works. Through the improved future studies of DRAM errors, simulation-based measurement of error correction capability will be more approximate to the real performance of manufactured DRAM.
