 As the advent of artificial intelligence (AI), the data transfer between the memory (e.g., DRAM, SRAM) and the processor (e.g., CPU, GPU) has increased dramatically [1]. This increased data transfer has revealed the limitation of the conventional Von Neumann architecture which separates memory and computing processors, such as power overhead while transferring data and a memory bottleneck issue due to the limited memory speed. To resolve these issues, a computing-in-memory (CIM) has been proposed. The CIM computes the data inside or near the memory so that the data does not have to be transferred to the processors, thereby reducing the data transfer rate and resolving power overhead issues. Another approach is an accelerator that models the AI algorithm to hardware devices. By modeling the AI algorithm, the device computes the data much faster and energy efficiently compared to the conventional processors.  Even though these approaches have been made to resolve the aforementioned issues, these approaches are not standardized which means more research is needed. Therefore, I want to study about the field which is up to date, however, it needs further research.     The advent of convolutional neural networks and deep neural networks has improved the performance of artificial intelligence (AI). To achieve high-performance AI, massive data transfers are required between processors and memories. As a result, the need for low-power and high-speed dynamic random access memory (DRAM) has increased [1]. However, the power consumption during the read operation of DRAM has increased due to high-speed. The main-source of the power consumption during read        operation is the input/output sense amplifier (IOSA) that detects data from long and high-capacitive global input/output lines (GIO) running through the DRAM. The power consumption of the IOSA is composed of the power consumed while discharging and pre-charging GIO (GIO power) and the power consumed solely by the IOSA (SA power). To reduce the power consumption of the IOSA, the self-timed and hybrid IOSA have been proposed that focus on reducing SA power. However, with the development of scaling technology, the threshold voltage (Vth) mismatch between the transistors increases that degrades the sensing yield of the IOSA. To overcome this degradation, a more larger input voltage is required that results in a more power consumption while driving GIOs. Therefore,    With the development of machine learning, data transfer rates between the processor and memory have increased dramatically, resulting in power overhead and memory bottlenecks in the conventional Von Neumann architecture. These problems have been addressed by improving the power efficiency of memories and changing the conventional architecture. The first approach focused on improving the power efficiency during the write operation of spin-transfer-torque magnetic random access memory (STT-MRAM) that requires high currents to change the magnetic tunnel junction (MTJ) used in STT-MRAM. To reduce the current consumption of write operations, write-termination (WT) circuits have been proposed to eliminate write operations as soon as the state of MTJ changes, indicating the data is written. These WT circuits have reduced the power consumed during the write operation by 49.6% [1]. Another approach to reduce the power consumption of memory is proposed by improving the energy efficiency of input/output sense amplifiers (IOSA) of dynamic random access memory (DRAM). By reducing the input voltage that is generated by driving a high capacitive global input/output line (GIO), the power consumption of IOSA has been reduced by 30% [2]. However, these approaches are only limited to the memory itself not considering the overall architecture. To reduce the power consumed during the data transfer between the processor and memory, a computing-in-memory has been proposed that allows computation inside the memory so that the data transfer rate can be reduced. The proposed work has used a conventional 6-transistor static random access memory (SRAM) and embedded low-swing analog processing at the SRAM array. As a result, the energy efficiency has increased by 10X and throughput by 5.3X compared to the conventional architecture. However, by using analog processing, the computation accuracy is unstable compared to digital processing. Therefore, another approach is proposed which focuses on developing an accelerator that only focuses on the computation of machine-learning algorithms. The proposed accelerator addresses not only the computation of algorithms but also memory systems that can minimize energy and area. Thus, the computation speed has increased by 117.87X and reduced the total energy consumption by 21.08X compared to the conventional Von Neumann architecture. These memory or architecture-focusing approaches have been made to mitigate the energy overhead with the advent of machine learning.  Through the advancement of machine learning algorithms, data transfer rates between processors and memory systems have increased dramatically, resulting in power overheads [1]. To address this power issue, multiple approaches have been made from the perspective of memory systems, and processors. In memory systems, several circuit designs have been made for Dynamic Random Access Memory (DRAM), and Spin-Transfer-Torque Magnetic Random Access Memory (STT-MRAM). For DRAMs, power overhead during read operations is highly dominant due to the input/output sense amplifier (IOSA) that detects data from a long, and high-capacity global input/output line (GIO) that runs through DRAM arrays. To reduce power overheads during read operations, offset cancel IOSA has been proposed that detects a smaller input voltage compared to the conventional IOSAs. By enabling the detection of a small input voltage, the voltage swing of GIO is reduced, which results in a power reduction. For STT-MRAMs, a high level of current is required to write the data, resulting in power overhead. To mitigate this issue, write termination circuits have been proposed to disable write operations right after the data is written [3]. However, these approaches do not reduce the data transfer rate. To reduce the data transfer rate, computing-in-memory architectures have been proposed that compute data inside the memory. Computations in memory are processed in the analog domain for energy and area efficiency [4].  In processors, neural processing units (NPUs) have been proposed that reduce data transfer rates by reusing the data and improve processing speed by parallel computation with digital domain [5].     RQ1. To what extent is a computing-in-memory architecture more effective than a digital accelerator in terms of machine learning accuracy? RQ2. To what extent are canceling out offsets more effective than employing a bigger transistor size of sense amplifiers in terms of the sense amplifier area? (Commonly, using bigger transistors reduces offsets but using offset cancelling also results in area overhead) RQ3. To what extent is using a 2's complement more effective than a sign-magnitude in terms of the power of analog-digital converter (ADC)? RQ4. To what extent is near-memory computing more effective than in-memory computing in terms of energy efficiency?  RQ5. To what extent is adding write termination circuits more effective than memory systems without write termination circuits in terms of write energy efficiencies?          In this way, this research project will consider the issue due to the increased data transfer rate to process advanced machine learning algorithms. Furthermore, this will introduce the approaches to improve the energy efficiency of memory systems and reduce the data transfer rate inside the memory or processor.         Recently, machine learning and artificial intelligence applications have been widely used in various applications. For instance, convolutional neural networks (CNNs) are used for computer vision (CV) and transformers are utilized for large-language models (LLMs). To ensure CNN accuracy and accurate responses from LLMs, large-scale data processing is required, and this requirement increases the data transfer rate between processors and memory systems. The increase in the data transfer rate causes a memory wall (or memory bottleneck) issue [1]. To address the memory wall/bottleneck, a processing-in-memory (PIM) architecture has been proposed that places processing elements (PEs) near the memory cell within the memory core. As a result, placing PEs in the memory core reduces data transfer distance and thereby increases energy efficiency. However, data transfer between memory cells and PEs remains dominant in PIM architectures [1]. Furthermore, in the case of dynamic random access memory (DRAM), the input/output sense amplifier (IOSA) consumes 10X energy compared to the bit-line sense amplifier (BLSA) [2]. In addition, in the spin-transfer-torque magnetic RAM (STT-MRAM), power consumption during write operations is dominant. For these reasons, the power consumption of the DRAM IOSA and STT-MRAM write operation needs to be optimized. Other than PIM architectures that use digital PEs, there are PIM architectures to compute multi-analog bits, which can boost the overall system throughput. However, these analog PIM architectures require analog-digital converters (ADCs) that consume most of the energy. However, their energy consumption can be optimized using 2’s complement of sign-magnitude   To reduce the data transfer rate between processors and memory systems processing-in-memory (PIM) architecture has been proposed that enables computation within the memory core without decreasing the measured accuracy of convolutional neural networks (CNNs) or transformers. Furthermore, PIM architectures require analog-digital converters (ADCs) to convert the analog computation result within the memory core to digitized result. This ADC dominates the power consumption in PIM architecture. However, ADC power can be optimized using 2’s complement or sign-magnitude. Moreover, ADCs can be removed by using digital processing elements (PEs) within the memory core, and the accuracy between analog and digital computation needs to be measured [1].  In the case of the input/output sense amplifier (IOSA) in dynamic random access memory (DRAM), the offset cancellation methods have been used to achieve robust sensing with small input voltages that reduce power consumption during IOSA read operation. The offset cancel methods can be done in two ways that are by utilizing a capacitor to store the mismatch between the transistors and by utilizing big-size transistors. These methods have trade-offs between the area and the offset cancel effect [2]. In addition, in the spin-transfer-torque magnetic RAM (STT-MRAM), the write operation dominates the power consumption. To address this problem, STT-MRAM utilizes write termination (WT) circuits that eliminate write operations immediately after the data is written [3]. However, the power consumption to sense the write operation causes power overhead, and this needs to be measured.           The analog and digital PIM architectures are modeled layers within CNNs. Thus, the measurement is done by writing the trained weight and transmitting input to the input port then the output is printed out through the output port of PIM architecture. The comparison is made between the software results and the computed result from PIM architecture.          In the case of ADCs, there are more reasons related to ADC’s power consumption other than 2’s complements and sign-magnitude methods. Because these two methods change how the memory cell computes the data. Therefore, more research is needed to compare these methods.   Answering these research questions requires energy efficiency, computation accuracy, and area. Considering RQ1, RQ3, and RQ4, these questions are related to in-memory-computing (IMC) which aims to enhance efficiency by reducing memory data transfer between processor and memory. The energy efficiency of IMC designs is largely influenced by ADCs, due to multiple comparators that consume considerable current. Furthermore, these IMC designs are employed as accelerators to process machine learning algorithms (e.g., ResNet20, ResNet50), and thus IMC designs require computation accuracy for certain tests (e.g., Cifar-10, ImageNet). Therefore, IMC designs target the energy efficiency of ADCs by using 2’s complement or sign-magnitude methods to reduce the number of comparators, and target the computation accuracy. Considering RQ 2, offsets of sense amplifiers (or comparators) are crucial for robust data sensing because offset can result in data read failures. To prevent data read failures, offset cancelation techniques to capture the offset of each transistor are employed. Alternatively, increasing the size of transistors can reduce variation factors that cause offset, but these two solutions have trade-offs, the former offset cancel technique can reduce offset better than the latter which increases transistor size but requires a considerably larger area than the latter. Therefore, an ideal sense amplifier should minimize offset while maximizing area efficiency.  In terms of RQ5, write energy efficiency is crucial for non-volatile memories (e.g., flash, magnetic random access memory) because large amounts of current are required for saving data. TWrite termination circuits are implemented to address write energy consumption by terminating write operations immediately after data is written. However, implementing write termination circuits results in area overhead. Therefore, ideal write termination circuits require an area efficiency of overall memory array structure.  The power consumption during input-output sense amplifier (IOSA) sensing operations has been an issue in dynamic random access memory (DRAM). To address the power concern, researchers have proposed self-timed and hybrid IOSA designs [1-2]. While these IOSAs effectively reduce the power consumption of the sense amplifier, these IOSAs overlook the power consumed while driving the global IO line (GIO), which transfers the voltage input to the IOSA. GIOs, run through the DRAM bank, GIOs have a large capacitance, leading to high power consumption. To mitigate this GIO power consumption issue, various approaches have been proposed Reference [4] implemented switches to GIOs to separately access near and far arrays, thereby reducing the GIO capacitance of near arrays. Another approach involves reducing the size of DRAM banks by splitting one bank into ⅓ and ⅔, stacking the former ⅓ with ⅓ of other DRAM banks [5]. While these approaches have succeeded in reducing GIO power consumption, they fail to account for the offset of the sense amplifier, hindering robust sensing of the IOSA. Robust sensing operations necessitate a larger voltage input through GIO, resulting in additional GIO power consumption. To address the offset of the sense amplifier, Offset Cancel IOSA (OC-IOSA) has been proposed, which removes the offset using capacitors [3]. However, transferring the voltage input via coupling through capacitors leads to input attenuation, necessitating a larger voltage input to compensate for the attenuation. Furthermore, the gate voltage is not driven to rail-to-rail voltage, resulting in static current and increased SA power consumption. In future work, an IOSA capable of mitigating both GIO and SA power consumption needs to be developed and considered. 
