Conventional computer architecture has a pon-noeumann architecture . Pon-nouemann architecture composed of two parts, memory and processing element (PE). This architecture has a advantage of simple structure, but has large power consumption when data transfer between memory and PE.  Compute-in-memory (CIM)  efficiently deals with aforementioned pon-nouemann architecture problems. CIM removes data transfer between memory and PE, then directly compute arithmetic logic in memory circuit (ex. SRAM, DRAM etc.). CIM alleviate the power consumption of pon-nouemann architecture by removing data transfer, but new problem of accurate calculation has become. My research goal is to improve the accuracy of CIM. The von Neumann architecture (i.e., Separation of memory and processing elements.) degrades both the speed and power of a chip. The operation of a computer is composed of three processes: (1) reading the data from memories and transferring the data to a processing element (PE) (2) operation in PE using data (3) writing the output of PE to memory. During data transfer between memory and PE in (1) and (3) processes, substantial power consumption and latency degradation can occur. Compute-in-memory (CIM) architecture locates the PE in the memory, thus eliminating processes (1) and (3). CIM architecture mainly conducts multiply and accumulation (MAC) operation of weight and input, which are used during deep neural network (DNN) training. The MAC operation in conventional CIM architecture is conducted in the analog voltage domain, so the final MAC output value is vulnerable to noise. As technology advances, DNN model sizes exponentially increase [1], such that accomplishing the target accuracy of CIM architecture becomes the main goal. I am interested in reducing noise during MAC operations by proposing a novel analog-to-digital-converter (ADC). The final analog voltage of MAC output is converted to digital code using ADC, the performance of the comparator used in ADC dominantly affects CIM accuracy. By compensating for the process variations of the ADC comparator, CIM accuracy can be improved.    In the realm of System-of-Chips (SoCs), the static random access memory (SRAM) used as embedded memory plays a crucial role in determining the speed, power, and size of chip [1]. As technology nodes are scaled down, cell density (i.e., number of cells per memory) increases. When memory density increases, the required SRAM failure probability decreases, resulting in an increase in the simulation costs necessary for accurate SRAM yield estimation [2]. Several methods for measuring the yield of SRAM have been proposed [3]-[7]. For example Brute-force monte carlo (BMC) [3] is a simple and intuitive method for estimating failure rates. However, BMC requires a particularly large number of samples to achieve high reliability. To reduce the large number of samples required by BMC, Quasi monte carlo(QMC)[4] has been proposed as an alternative method for estimating failure rates. QMC typically uses a specific performance metric (e.g., read static noise margin) to represent the stability of SRAM operation, then based on the received distribution of performance metric, failure rates can be estimated with relatively few samples. However, since most performance metrics do not follow the expected distribution in the tail end of the distribution, QMC is inaccurate when calculating low- probability events that are computed at the tail end of the distribution. Most probable failure point (MPFP) search [5] is another method for estimating SRAM failure rates. MPFP represents the failure sample with the highest failure probability in the variation parameter space (e.g., Vth, effective channel length, capacitance etc). After an MPFP is found, researchers can estimate the overall failure probability of variation parameter space [8]. While various MPFP search methods were proposed in [5]-[7], these method does not provide an accurate estimation of the yield because it approximates the failure boundary linearly.  References  [1]K. Cho et al., “SRAM Write- and Performance-Assist Cells for Reducing Interconnect Resistance Effects Increased With Technology Scaling,” IEEE Journal of Solid-state Circuits, vol. 57, no. 4, pp. 1039–1048, Apr. 2022, doi: https://doi.org/10.1109/jssc.2021.3138785.  [2 ]H. Jeong et al., “Offset-Compensated Cross-Coupled PFET Bit-Line Conditioning and Selective Negative Bit-Line Write Assist for High-Density Low-Power SRAM,” IEEE Transactions on Circuits and Systems I: Regular Papers, pp. 1–9, 2015, doi: https://doi.org/10.1109/tcsi.2015.2388837.  [3]  F. Gong, Y. Shi, H. Yu, and L. He, "Parametric yield estimation for SRAM cells: Concepts, algorithms and challenges," in Design Automation Conference, Knowledge Center Article, 2010: Citeseer, pp. 1-13.  [4] E. Grossar, M. Stucchi, K. Maex, and W. Dehaene, “Read Stability and Write-Ability Analysis of SRAM Cells for Nanometer Technologies,” IEEE Journal of Solid-State Circuits, vol. 41, no. 11, pp. 2577–2588, Nov. 2006, doi: https://doi.org/10.1109/jssc.2006.883344.  [5] ] T. Kida, Y. Tsukamoto, and Y. K. Renesas, "Optimization of importance sampling Monte Carlo using consecutive mean-shift method and its application to SRAM dynamic stability analysis," in Thirteenth International Symposium on Quality Electronic Design (ISQED), 2012: IEEE, pp. 572-579.  [6] T. Haine, J. Segers, D. Flandre, and D. Bol, "Gradient importance sampling: An efficient statistical extraction methodology of high-sigma SRAM dynamic characteristics," in 2018 Design, Automation & Test in Europe Conference & Exhibition (DATE), 2018: IEEE, pp. 195-200.  [7] D. D. Weller, M. Hefenbrock, M. S. Golanbari, M. Beigl, and M. B. Tahoori, "Bayesian optimized importance sampling for high sigma failure rate estimation," in 2019 Design, Automation & Test in Europe Conference & Exhibition (DATE), 2019: IEEE, pp. 1667-1672.  [8] S. Sankararaman, M. J. Daigle, and K. Goebel, "Uncertainty quantification in remaining useful life prediction using first-order reliability methods," IEEE Transactions on Reliability, vol. 63, no. 2, pp. 603-619, 2014.   Embedded-DRAM (eDRAM) stores data using floating nodes like transistor gates or drain capacitors. Floating nodes are susceptible to current leakage, because due to the absence of driving sources which maintain voltage levels at certain nodes. Thus, eDRAM requires periodic refresh operations, which rewrite the data. The time during which data stored at eDRAM cells remains without refresh operations is referred to as the data retention time (DRT). The increase of floating nodes’ capacitance leads to the increase of the DRT. However, as transistor length scales down to 28nm, the capacitance of floating nodes is decreasing gradually. For example, In a 28nm CMOS technology node, the mean of DRT is 20us [1]. The value of DRT does not follow the uniform distribution but has the gaussian distribution. Thus, in a memory array consisting of multiple eDRAM cells, the array is considered defective if the DRT of any single cell is shorter than the refresh cycle. Achieving higher yield (i.e., the ratio of the number of arrays with defects to the total number of arrays) requires longer DRT of cells. …..  RQ1. To what extent can the eDRAM cell capacitance be increased to achieve a 20us DRT in a 28nm CMOS process?  RQ2. To what extent does the average DRT in microseconds exceed to meet a target yield of 99% in 14nm FinFET?  RQ3. RQ4.      Embedded-DRAM (eDRAM) stores 1-bit data (i.e., 0 or 1) using floating nodes. As depicted in Fig. 1, when a word-line (WL) signal is asserted, a voltage difference (VBL) occurs between the bit-line (BL) and half of VDD (HVDD). If VBL exceeds Half VDD (HVDD), a sense-amplifier (SA) detects that the cell stores data consisting of ‘1’. On the other hand, when VBL is smaller than HVDD, SA detects data consisting of ‘0’. Although eDRAM  stores data consisting of ‘0’, SA does not always detect data correctly. Since floating nodes are used to store data, eDRAM is susceptible to leakage current and thus data retention time (DRT) is the standard time required for a refresh to rewrite the data in eDRAM. Whenever each eDRAM cell consisting of a memory array has process variation (e.g., threshold voltage, effective channel length etc.), as a result each eDRAM has a different DRT. If only one eDRAM cell’s DRT is shorter than the refresh cycle, the whole memory array is regarded as defective. Thus, the larger memory density, the lower memory yield.         In 28nm CMOS technology, a proposed 4T1C eDRAM DRT has a gaussian distribution (mean = 75 us, std = 15us) [1]. In this case, memory yield is represented as follows:                                      (2)  N refers to the number of eDRAM cells, and Pfail refers to the failure probability of eDRAM cell. The refresh cycle is fixed at the design stage. When information about DRT distribution is available, memory yield can be obtained using eq(1) and (2). For example, 4T1C eDRAM DRT exhibits the aforementioned distribution, where the memory array has 1k bit, and the refresh cycle is set to 30us. In this case, Pfail is 0.0014 and Yield is 0.2464. As represented in eq (1) and (2), when we fix the design target of yield, N, and refresh cycle, the required DRT distribution is obtained.          The yield of embedded-DRAM (eDRAM) is determined by the three factors: memory array size, refresh duty, and distribution of eDRAM cell’s DRT. Among the factors, refresh duty and cell’s DRT are particularly important when estimating the yield of memory, since memory array size is usually determined by the memory density. The yield of memory is expressed as follows:    Pfail =-1((u-Tref)/)                -  (1) Yield = (1-Pfail )Nbit                -  (2)  Where  indicates inverse normal distribution, Pfail indicates failure rate of an eDRAM cell, Tref refers to refresh duty, u refers to mean of DRT,  indicates the standard deviation of DRT, and Nbit refers tto the memory array size. For example, in the case where Tref is 20us, Nbit is 1k, u is 40us, and  is10us, the Pfail is expressed as 2. In 28nm CMOS technology, the eDRAM memory density usually ranges from 16kb to 32kb, and especially in the 4T1C [1] eDRAM case, the refresh duty is already set to 40us. Therefore, the required DRT distribution for satisfying 99% target yield is obtained from (1) and (2). In 16kb and 32kb case, the required DRT result is (95us, 10us) and (105us, 10us), respectively.     The main purpose of designing a compute-in-memory (CIM) architecture is to enhance figures of merit (FoMs). The FoMs for CIM are largely determined by three factors: operation (i.e., multiply and accumulate) throughput, memory density, and power consumption. When comparing conventional CIM architectures with the proposed architecture, important FoMs include tera-operation-per-seconds (TOPS) per watt (TOPS/W) and TOPS per memory density (TOPS/mm2).  CIM architecture, operating in the analog-domain, exhibits two advantages compared to CIM architecture in the digital-domain: high throughputs (i.e., high TOPS) and high memory density without requiring additional digital computing units, thus a high TOPS/W rate and a high TOPS/mm2 rate may occur. However, compared to digital-domain CIM, the analog-domain necessitates the use of the multilevel voltage domains, attributing to the vulnerability to process-voltage-temperature (PVT) variations. Therefore, analog-domain CIM has a disadvantage of accuracy loss. Designing a PVT tolerance architecture to increase accuracy requires additional circuit techniques, resulting in the decreases of TOPS/mm2 rate. Thus, circuit engineers designing CIM architectures compromise with respect to a trade-off between accuracy and TOPS/mm2 in an effort to optimize their design goal. 
