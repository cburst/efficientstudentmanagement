Cameras are fundamental tools for peopleâ€™s everyday life from capturing a selfie with a smartphone, automatic driving, and surveillance camera for security. Along with the increase in its demands, cameras with more diverse functionalities are required, such as depth and hyperspectral imaging and there are fundamental trade-offs between its performance, size and cost. To overcome these trade-offs, I jointly design hardware and software of cameras which are also referred to as the field of computational optics. The most attractive point of my research is to visualize the information surrounding us. From this visualization, I believe people can enlarge their perception of their daily lives. The most challenging part of my work is that it is an interdisciplinary field that requires the knowledge of optics, mathematics, computer vision, and sometimes biology to analyze the results. I believe that collaborating with others is crucial to get high impact research in my field and, at the same time, I can enhance my interdisciplinary knowledge with great communication.  Conventional imaging systems exhibit a trade-off between their imaging performance such as field-of-view (FOV), resolution, and frame rate, due to the physics of light propagation. In the field of computational imaging, researchers seek to overcome this limitation of conventional optics by jointly designing optics and image processing algorithms. With the advent of computational imaging, various imaging applications such as superresolution microscopy, quantitative phase imaging, and in-vivo microscopy have been demonstrated to successfully image biological samples that had not been successfully imaged before. Initially, Zheng et al. [1] develop a computational imaging technique to overcome a general challenge for conventional microscopes, which exhibit a trade-off between FOV and resolution. Zheng et al. utilize low magnification objective lenses for a wide FOV and develop an algorithm to computationally synthesize the optical resolution of the resulting image by combining multiple measurements illuminated at varying angles. Zhou et al. [4] expand this technique with the use of an array of microscopes, termed multi-camera array microscopes (MCAM). Meanwhile, Katz et al. [3] try to computationally address the scattering property of the tissue for non-invasive in-vivo imaging, which was not possible with conventional optics. Xu et al. [5] develop these techniques further by using a SPAD camera which exhibits high sensitivity and high frame rate imaging capability. Furthermore, Antipa et al. [2] exploit random properties of scattering media to build a lensless camera where the lens is replaced by a thin scattering diffuser. Though diffusers scramble input signals, the author demonstrates that their device is better for recovering 3D information of the scene. More recently, Wang et al. [6] develop a phase mask by designing the degree of randomness of scattering media and utilize it for realizing optical neural networks that can optically encode the scene at the speed of light. Likewise, computational imaging holds great promise in aiding the development of efficient imaging tools and facilitating the observation of scientific phenomena beyond the capabilities of traditional optics. A plethora of cameras continues to be installed in homes to serve various purposes, including monitoring pets, facilitating online calls, and interacting with home appliances. Although these cameras enhance user convenience by utilizing the information they collect from users, they also proportionally increase the vulnerability to cyber-attacks. While camera data can be encrypted through software, the software based encryption does not fundamentally prevent direct attack to hardware. Therefore, finding ways to increase the security of home cameras without compromising the utility of the collected information is crucial in the era of internet of things (IOT) devices.  Q1. To what extent does utilizing lensless cameras reduce the risk of IOT devices being cyber attacks compared to commercialized miniaturized cameras? Q2. How significantly can advancements in image processing techniques influence camera designs to mitigate the risk of cyber attacks on IOT devices?  Lensless cameras leverage an imaging technique where the lens is replaced by a thin film. Since these cameras inherently encrypt the information at the hardware level, the information from the scene gets scrambled and becomes unidentifiable by the image sensor, potentially enhancing security against cyber attacks. Meanwhile, the scrambled information can be decrypted using a pre-calibrated hardware key, which is determined by the microscopic structure of the thin film [1]. Thus, my research questions both focus on finding a balance between hardware security and imaging quality by designing the microscopic structure of the film. Furthermore, in the context of IOT, where not all cameras necessitate image display, optimizing the mask structure enables these devices to act as specialized sensors for various applications like detecting a cat's location or assessing user moods.    To enhance the cybersecurity for internet of things (IoT) cameras, the primary goal of this research project is utilizing encrypted sensor data to perform specific tasks without reconstructing the scene from raw measurements. In this regard, deep learning-based methods are known to be effective for performing particular imaging tasks, such as detecting a user's location or assessing their mood. To validate this proof of concept, I will create a model capable of simulating the measurements from image sensors in lensless cameras. To be specific, a synthetic paired dataset of encrypted raw measurements and detection points can be generated by utilizing an open-source dataset for user location detection. Subsequently, a deep learning network can be trained to perform the point detection task using a paired dataset. Through this process, this framework enables the comparison of security features between the proposed lensless cameras and traditional camera systems and identifies the enhanced security features of lensless cameras.   Lensless imaging is a technique where a lens is replaced by a thin film that randomly modulates the incident light, resulting in unidentifiable measurements from the image sensor. Additional image reconstruction algorithms must be applied to recover the scene using a pre-calibrated key that represents the characteristic function of the film. Since lensless imaging encrypts the information of the scene at the hardware level, it has been increasingly applied to security applications. Most work related to lensless imaging has focused on the reconstruction quality of the recovered scene.  Instead, my work will focus on utilizing a lensless camera as a sensor to perform specific imaging tasks, rather than concentrating on scene recovery. More specifically, we will design an imaging system that can extract human poses. To achieve this, deep learning will be employed to decipher information from the encrypted scene. By doing so, we can develop a high-security sensor that detects human poses without accessing direct information about the human.  Limitation remains in relation to cyber attacks even when using lensless cameras. While lensless imaging technique is useful for performing specific imaging tasks while avoiding direct access to the information of the entire scene, the information can be decoded if the hardware key is leaked. Additionally, the hardware key can be hacked if hackers access a certain amount of data from the lensless camera, which is also known as a plaintext attack.   To address this problem, the hardware key, which is determined by the characteristic function of the film, can be designed with increased complexity enhancing the encryption parameters. For example, the film can be engineered to exhibit different responses at various incident angles of light. In other words, each position within the field of view requires a unique key for recovery. By employing this strategy, the complexity of the hardware key can be increased depending on the number of shift variances. Then, with the development of a corresponding deep learning estimator, we hope to develop an imaging system that performs numerous imaging tasks while maintaining a high-security level by encrypting the scene for future studies.
