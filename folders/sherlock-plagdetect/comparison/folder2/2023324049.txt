The importance of Super-Resolution (SR) techniques is growing larger as the demand for high quality image data increases. I chose to study SR technologies because of my interest in photography. Though the camera's technological aspect is important as well.  As the growing number of smartphone cameras replace the position of  DSLRs and mirrorless cameras in the general consumer market, the production of digital cameras has drastically declined. Since smartphones have a smaller sensor size compared to digital cameras, SR technology implementation is necessary. One of the main problems for SR to solve is to recover the images that were hindered externally. In the case of autonomous vehicles, they encounter a variety of weather environments such as fog, snow and other phenomena which hinders the overall quality of the image. But the SR technology shows poor results at mathematically indistinct problems.  I am investigating a learning-based module for the multiframe Super-Resolution (SR) technique. Multiframe SR is a technique which aims to combine several Low-Resolution (LR) images to reconstruct one High-Resolution (HR) image. By combining multiframe SR with learning-based techniques, HR reconstruction is performed automatically, thereby showing superior results compared to traditional multiframe SR. Traditional multiframe SR uses mathematical features of each frame individually, where learning based methods learn the overall interrelationships of the frames which are stored in the module. The overall interrelationships allows for a fluent reconstruction process in cases of highly degraded images. Blurry, low light noisy images, which are usually taken from smartphones can be considerably enhanced using this technique. The industrial development also reinforces the anticipation for this technique. Smartphones improved application processors (AP), and camera manufacturers switched over to stacked Complementary Metal Oxide Semiconductor (CMOS) sensors. The enhanced AP enables smartphones to process learning-based multiframe SR real-time, and stacked CMOS sensors enable rapid continuous shots in high quality.  Prompt: Describe several notable publications related to your academic field or research interest. How did those publications influence work in the field? How do you intend to build upon the foundation established by others? (Make sure to start with a topic sentence and end with a closing sentence)  To reconstruct High-Resolution (HR) images from Low-Resolution (LR) images, diverse Super-Resolution (SR) technologies had been proposed until recently. Former SR techniques only suggested partial enhancements in reconstruction, though it was necessary to reconstruct HR images considering overall enhancements. Hardie et al, initially proposed the Multiframe Super-Resolution (MFSR) technique that includes the overall enhancement [1], by combining multiple LR images with alignment module and fusion module based on L2 normalization. Farsiu et al, proposed a faster and more robust MFSR technique based on L1 normalization, which showed superior performance in denoising compared to Hardie's method [2]. Google’s Handheld multiframe SR is the most recent methodology where alignment and fusion is calculated by structure tensor [3]  Recently, Learning-based Single Image based SR (SISR) shows impressive results by learning the image prior information from diverse training images. One example of SISR is EDSR [4] which shows superior results, though it does not use multiple LR input images.   Learning-based MFSR shows state-of-the-art results, for combining both advantages of learning-based SISR and MFSR. By fusing the multiple LR input images, with prior information trained from the broad dataset, learning-based MFSR shows superior results in real time applications. Deep Burst Super-Resolution (DBSR) is one of the breakthroughs in learning-based MFSR, which is the first module to implement the Burst-dataset for real-time MFSR[5].   Although there exist many evaluation standards for image quality, noise reduction and high frequency information reconstruction are most suitable for super resolution (SR) evaluation . In order to achieve the best performance in relation to noise reduction and HF information restoration, peak signal-to-noise ratio (PNSR) and structural similarity index measurement (SSIM) are implemented for image quality assessment. PSNR measures image quality by comparing a super resolution (SR) image with a high resolution (HR) image using mean squared error (MSE). On the other hand, SSIM is measured by comparing the mean and variance of image components, which mainly consist of luminance, contrast, and structure. The characteristics of MSE leads PSNR to achieve substantial sensitivity in noise detection, while SSIM achieves significant performance in assessing the overall difference of image through mean and variance. Because of the mathematical characteristics of PSNR and SSIM it becomes the main measurement to address the research questions 1 and 2, by directly providing implication of SR performance. Since scalar values are given as direct implication for PSNR and SSIM, it could be implemented as loss function for multiframe SR (MFSR) algorithm. By combining PSNR and SSIM, the learning based SR algorithm can be optimized to achieve best performance in noise reduction and HF reconstruction. For further implementation, in ablation study, implementing PSNR and SSIM as loss function can provide direct result comparison to determine which module could be optimized to certain loss values. Both in loss calculation and implication for noise reduction and HF reconstruction, PSNR and SSIM provide significant guidance for SR reconstruction.    The aim of the proposed multi-frame super resolution (MFSR) is to achieve the highest performance of RQ1-2. For our proposed method to achieve that performance, the result of Peak signal-to-noise ratio (PSNR) and Structural similarity index measure (SSIM) performance should outperform other existing methods [2]. This outperformance can only be achieved by the proposed method when the delicate combination of low resolution (LR) images produce a super resolution (SR) image that is visually indistinguishable to the ground truth[3].  In recent studies, the LR image combination process is divided into the alignment and fusion process. Both processes are distinctly implemented with learning modules optimized for each task. Pyramidal structures are the state-of-the-art (SOTA) method for alignment [4], where estimation of the alignment is concatenated from robust LR feature to precise HR feature. Alongside, the Attention mechanism shows the SOTA performance [1] by selectively fusing LR images with high correlations. Since the alignment part doesn’t exhibit substantial impact on the enhancement [1], our proposed methods are expected to share the pyramidal alignment of former modules, but introduce novel approaches in the fusion process. The ablation study of RQ3 is necessary to exhibit the performance of the proposed fusion module. In conclusion, our proposed module aims to achieve superior performance in terms of the quantitative measurements of SSIM and PSNR. While inheriting the traits of pyramidal feature alignment, implementation of novel fusion modules would be suggested.  Although the proposed learning-based Multiframe super Resolution (MFSR) method aims to achieve state-of-the-art (SOTA) performance of Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index Measure (SSIM), it has the possibility of facing challenges in terms of quantitative analysis and real world applications. In the study of comparing the mathematical characteristics of PSNR and SSIM, Hore et al discovered that the quantitative measurement differs from the degraded features of images. implying that the SOTA quantitative performance does not always guarantee visually satisfying images. To address this issue, Zhang et al proposed Learned Perceptual Image Patch Similarity (LPIPS) metrics, providing quantitative scores which imitate human visual evaluation. With the additional LPIPS metric, the proposed metrics is expected to produce more visually satisfying results.  Though learning based SR produces qualitatively satisfying results, the issue of hallucination still remains, which refers to the visually satisfactory that are far from the ground truth. Where vanilla MFSR methods only optimize the SR results based on given LR inputs , learning based MFSR produces Super Resolution (SR) images by combining multiple low resolution (LR) images based on the training priors. The corrupted priors produce hallucinations which cannot be adjusted on real time applications. Learning based regularization terms is considered as a valid candidate, but further research is required.
