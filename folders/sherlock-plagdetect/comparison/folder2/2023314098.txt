My academic field is chip design using resistors, capacitors, inductors and mosfets. In detail, high-speed serial link design between computing units and memory is the main topic. As increased demands for high speed computing by artificial intelligence and virtual reality, market requires ultra high speed interfaces which operate over 200Gb/s. However, in reality, the speed improvement of memory is very slow compared to computing units. This phenomenon is called ‘memory wall’ which means memory is the bottleneck of the whole system. Recently, high bandwidth memory (HBM) was developed to resolve the aforementioned challenges. Conventional dynamic random access memory structure uses 2-dimensional (2-D) structure which uses wire bonding. While 2-D structure has a limited number of interconnections, HBM uses 3-dimensional (3-D) structure which connects DRAM vertically using through-silicon via (TSV). Since I am interested in this new memory technology, I decided to study for further. As machine learning, virtual reality and automatic driving platforms require numerous computing operations, users require high performance computing systems. Computing architecture mainly consists of computing units (e.g., central processing unit ;CPU and graphic processing unit ;GPU) and memory (e.g., dynamic random access memory ;DRAM) and static random access memory ;SRAM). Therefore, to improve the performance of system performance, not only are high-performance computing units necessary, but also high-performance memory. However, in reality, the development speed for memory is slower than for computing units. Although circuit designers succeed in developing high performance processing units, the improvement of the whole system is limited by memory performance. To resolve the aforementioned problem, high-bandwidth memory (HBM) is developed with advanced technology such as 3-dimensional (3-D) stacking structure [1]. Conventional memory uses 2-dimensional (2-D) structures and wire-bonding which limit the density and bandwidth. HBM uses 3-D structures and through-silicon via (TSV) to increase the density and bandwidth of memory dramatically. These advanced memories can support a software program which requires over billions of operations. For these reasons, HBM is a key product for future computing architectures and I research that.   Memory circuit designers seek to improve  performance in two directions: (1) Developing advanced design techniques and (2) Revising memory structures using advanced packaging technologies. For direction (1), before the work of memory using pulse amplitude modulation (PAM) techniques is proposed [1], the conventional memory uses non-return-to-zero (NRZ) signaling to transmit/receive data. NRZ signaling can provide 1-bit information in 1-symbol, which means the data rate equals clock frequency [2]. In recent decades, the speed of memory has increased dramatically though increasing clock frequency appears impossible. To address the frequency limitation issue, PAM signaling was adopted in memory interfaces [1],[3]. PAM-4 signaling can send 2-bit information in 1-symbol, which means the data rate is 2 times faster than before, at the same clock frequency [1]. However, PAM-4 signaling has a low signal-to-noise ratio (SNR) because voltage margin is one-third that of NRZ signaling. To mitigate this discrepancy, researchers proposed PAM-3 signaling that combines the merits of NRZ (e.g., high voltage margin) and PAM-4 (e.g., higher data rate) [3]. Since PAM-3 sends 1.5-bit in 1-symbol, theoretically, this method exhibits 150% pin-efficiency. However, when it is used in the memory interface, pin-efficiency decreases to 133% due to the dummy bit. To utilize this dummy bit as practical information, partial data bus inversion (DBI) encoding is proposed that uses the dummy bit for DBI signaling instead of allocating additional pins [4]. For direction (2), in recent years, researchers developed 3-dimensional (3-D) stacking technologies to overcome the bandwidth limitation of conventional 2-dimensional (2-D) memory structures. In conventional 2-D structures, the memory cell density is increased as the scale of the memory cell become smaller. [5]. However, due to saturation of technology scaling, the memory cell density is also saturated. To increase the cell density, researchers developed through-silicon via (TSV) by stacking the memory in the vertical direction [6]. Additionally, advanced packaging technologies have emerged which can make the distance between chip and memory short [7]. The bandwidth of memory which is limited by channel length can be increased ten times.. With aforementioned advanced technologies, the memory performance can be doubled every two years [8].  References: [1] Cho, Wei-Han, et al. "10.2 A 38mW 40Gb/s 4-lane tri-band PAM-4/16-QAM transceiver in 28nm CMOS for high-speed Memory interface." 2016 IEEE International Solid-State Circuits Conference (ISSCC). IEEE, 2016.  [2] Bae, Seung-Jun, et al. "An 80 nm 4 Gb/s/pin 32 bit 512 Mb GDDR4 graphics DRAM with low power and low noise data bus inversion." IEEE journal of solid-state circuits 43.1 (2008): 121-131.  [3] Park, Hyunsu, et al. "30-Gb/s 1.11-pJ/bit single-ended PAM-3 transceiver for high-speed memory links." IEEE Journal of Solid-State Circuits 56.2 (2020): 581-590.  [4] Han, Chanheum, Ki-Soo Lee, and Joo-Hyung Chae. "13.9 A 25.2 Gb/s/pin NRZ/PAM-3 Dual-Mode Transmitter with Embedded Partial DBI Achieving a 133% I/O Bandwidth/Pin Efficiency and 19.3% DBI Efficiency." 2024 IEEE International Solid-State Circuits Conference (ISSCC). Vol. 67. IEEE, 2024.  [5] Bae, Seung-Jun, et al. "An 80 nm 4 Gb/s/pin 32 bit 512 Mb GDDR4 graphics DRAM with low power and low noise data bus inversion." IEEE journal of solid-state circuits 43.1 (2008): 121-131.  [6] Lee, Dong Uk, et al. "25.2 A 1.2 V 8Gb 8-channel 128GB/s high-bandwidth memory (HBM) stacked DRAM with effective microbump I/O test methods using 29nm process and TSV." 2014 IEEE International Solid-State Circuits Conference Digest of Technical Papers (ISSCC). IEEE, 2014.  [7] Ko, Han-Gon, et al. "6.7 An 8Gb/s/µm FFE-Combined Crosstalk-Cancellation Scheme for HBM on Silicon Interposer with 3D-Staggered Channels." 2020 IEEE International Solid-State Circuits Conference-(ISSCC). IEEE, 2020.  [8] Hollis, Timothy M., et al. "Recent evolution in the DRAM interface: Mile-markers along memory lane." IEEE Solid-State Circuits Magazine 11.2 (2019): 14-30.  In recent decades, numerous researches have been presented to improve the speed of memory interfaces based on non-return-to-zero (NRZ) signaling methods [1]. Although circuit techniques based on NRZ have been developed continuously over 25 giga-bit per second (Gbps), furthur speed improvements are saturated by the clock frequency limitation (i.e., Maximum clock frequency is limited by speed of technology). To overcome this limitation, various pulse-modulation amplitude (PAM) signaling methods (i.e., three-level, PAM-3 and four-level, PAM-4) are used in memory interfaces. Given that PAM-4 signaling method allows for sending 2-bit information in 1-symbol (i.e., means that pin-efficiency is 200%), the bandwidth of the interconnect can be doubled compared to NRZ signaling without increasing the clock frequency. However, PAM-4 has a three times lower voltage margin (i.e., same with least significant bit value), which substantially influences on bit-error-ratio performance compared to NRZ. To mitigate characteristics of PAM-4 and NRZ, researchers have proposed the PAM-3 signaling method that sends 3-bit information in 2-symbol of which theoretical pin-efficiency is 150%. However, the practical pin-efficiency of PAM-3 is degraded, considering the characteristics of memory interfaces which transmit/receive the data using burst length which has the 2 to the power of N (i.e., cannot be divided by three in integer format). Therefore, researchers should consider various design conditions to design memory interfaces using PAM-3 signaling.  RQ1. To what extent do PAM-3 signaling methods improve memory speed compared to NRZ signaling? RQ2. To what extent does mismatch between practical and theoretical value of pin-efficiency when PAM-3 signaling is adopted in the memory interface degrade the memory speed? RQ3. To what extent is the speed improvement of multi-level signaling better than the degradation bit-error-rate performance of multi-level signaling in terms of power consumption? RQ4. To what extent do PAM-3 signaling methods degrade the bit-error-rate performance compared to NRZ signaling using the same power consumption?  The evaluation of performance of of signaling methods, such as non-return-to-zero (NRZ), three-level pulse amplitude modulation (PAM-3), and four-level pulse amplitude modulation (PAM-4), signal integrity analysis (i.e., the most influence to bit-error-rate ;BER) utilizing signal-to-noise ratio (SNR) and Nyquist frequency are required [1]. Since symbol-rate is proportional to clock frequency, NRZ requires 150% and 200% higher speed clock frequency than PAM-3 and PAM-4 respectively to maintain the same data rate. As PAM signaling can decrease channel loss which is reversely proportional to clock frequency, the signal integrity increases. However, to send multi-bit information in a 1-symbol, the voltage difference between adjacent levels decreases. In case of PAM-3, voltage margin which is equal to the least voltage difference between levels, is one over two of NRZ and is one over three of NRZ in case of PAM-4. This means that PAM-3 and PAM-4 have lower SNR 6dB and 9.54dB compared to NRZ. Considering the above analysis, the signaling method is decided to achieve the highest BER. As the recent demands for high speed interface increase, the clock frequency also increases from 1GHz to 13.5GHz [2]. The increase of clock frequency over 10GHz+ needs a higher cost to compensate for the channel loss to maintain the signal integrity. To solve this problem, recent published research uses the PAM-4 signaling method [3]. PAM-4 signaling is good in respect to channel loss because it has lower Nyquist frequency. However, the voltage difference is too low to maintain the signal integrity considering power supply noise and simultaneous switching noise. To mitigate the above problems, PAM-3 signaling is used which has 50% higher voltage difference than PAM-4 and 33.3% lower clock frequency than NRZ [4]. However, due to burst mode which sends data 2 to the N power (i.e., cannot be divided by 3), PAM-3 signaling has a mismatch of pin-efficiency between practical (133 %) and theoretical (150 %) [5]. Considering the memory interface characteristics, the PAM-3 signaling can improve the interface speed 33% higher than NRZ with the same clock frequency. Utilizing the dummy bit which is generated by pin-efficiency mismatch, is the key point of PAM-3 signaling to reduce the power consumption.        PAM-3 signaling has the potential to improve memory interface speed at the same clock frequency while reducing power consumption by simplifying the clock path complexity, which is directly proportional to the clock frequency [1]. However, due to burst mode of memory, which sends 2 to the power of N of data(a number which cannot be divided by 3), the dummy bit which does not have any information is appear (i.e., 9-bit data is needed to send 8-bit data). A mismatch between theoretical and practical pin-efficiency degrades the speed of a memory interface. As a result of the dummy bit, the speed improvement compared to NRZ signaling degrades from 150 % to 133 % [2]. Therefore partial data bus inversion (pDBI) is proposed to reduce the power consumption of the output driver utilizing the dummy bit as a DBI signal. Since the pDBI signal reduces the bit density of high from 25% to 20%, the signaling current of the output driver is reduced by 20%. Although pDBI can improve the system performance in terms of power consumption, it cannot improve the signal integrity, which is more important in terms of bit-error-rate (BER). To improve both performance metrics, 4-bit 3-wire 3-level (4B3W3L) multi-wire encoding scheme is proposed for PAM-3 signaling in memory interface. Since 4B3W3L limits the number of maximum transitions which consumes large power, it can reduce the power consumption of the output driver by 18.9%, which is similar to the result of [2]. In addition, due to the reduced effects of simultaneous switching output noise (SSN) which is proportional transition level, the signal integrity is also improved. The eye-width of the upper eye (i.e., performance metric indicates the signal integrity) improved by 23 % and of the lower eye improved by 7 % compared to the results of [1-2]. In conclusion, the 4B3W PAM-3 encoding improves the system performances in both respects power and signal integrity.  Recent memory interfaces feature three-level pulse-amplitude-modulation (PAM-3) signaling to increase data rate of interface [1-2]. Conventional PAM-3 signaling employs a 3-bit per 2 unit interval (UI) encoding scheme, but due to the fact that memory interfaces send 2^N data, which cannot be divided by 3 which means 9 bits is needed to send 8-bit information, a dummy-bit is generated, which degrades memory speed. To utilize the dummy-bit as practical information, this research project proposes a 4-bit 3-wire 3-level (4B3W3L) encoding scheme, which reduces the maximum transition probability. For this reason, the 4B3W3L encoding scheme can improve the horizontal eye-margin by 23% of the upper eye and by 7% of the lower eye. Additionally, the power consumption of the output driver is reduced by 18.9%. Although the 4B3W3L encoding scheme  is an efficient scheme in terms of signal quality and power consumption, this scheme has two drawbacks: (1) vulnerable to per-pin skew and (2) larger area overhead of encoder/decoder than conventional PAM-3 encoding scheme. Since the 4B3W3L encoding scheme uses the 1-symbol and 2-channel per 3-bit (i.e., multi-wire signaling)  instead of 2-symbol and 1-channel per 3-bit (i.e., multi-window signaling), the per-pin skew, which refers to variations between the correlated channels, degrades the bit-error-rate (BER) which affects reliability. Additionally, the increased number of input and output require the complex encoder/decoder. By increased circuit complexity, the area overhead and power consumption of the encoder/decoder increase. Further research should be conducted to overcome the vulnerability to per-pin skew and complex encoder/decoder structure.  [1] Yang, Jaehyeok, et al. "13.1 A 35.4 Gb/s/pin 16Gb GDDR7 with a Low-Power Clocking Architecture and PAM3 IO Circuitry." 2024 IEEE International Solid-State Circuits Conference (ISSCC). Vol. 67. IEEE, 2024.  [2] Cho, Sung-Yong, et al. "13.6 A 16Gb 37Gb/s GDDR7 DRAM with PAM3-Optimized TRX Equalization and ZQ Calibration." 2024 IEEE International Solid-State Circuits Conference (ISSCC). Vol. 67. IEEE, 2024.
